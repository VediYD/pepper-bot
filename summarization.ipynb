{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82aaecb-5f45-4df6-acb1-cbd802c3ac0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f818b87-57dd-4a6e-8807-a45277615675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6035a85-3a3e-4f81-aeb9-27313465b502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f30cea-436b-4402-ae30-9ad62220fcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58cb1b6-acc6-41cd-87c1-4a8e4dedca1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5036d-d506-4a6f-81cc-9e904e937ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e0f880-a864-46db-9daa-ed937af9087c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec9e4d-5ee4-4ebd-b0f1-2444af36e7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9e380-6883-4034-9745-a7971cefad8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c28cd5c-0b29-403a-bcdd-09d2a01b3eea",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a544b1-9b97-4dd3-8416-e25be2f74790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gpt4all import GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4eb9cb9-767a-42af-8e94-ef95fd5f1446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /app/ggml-gpt4all-j-v1.3-groovy.bin\n",
      "gptj_model_load: loading model from '/app/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
      "gptj_model_load: n_vocab = 50400\n",
      "gptj_model_load: n_ctx   = 2048\n",
      "gptj_model_load: n_embd  = 4096\n",
      "gptj_model_load: n_head  = 16\n",
      "gptj_model_load: n_layer = 28\n",
      "gptj_model_load: n_rot   = 64\n",
      "gptj_model_load: f16     = 2\n",
      "gptj_model_load: ggml ctx size = 5401.45 MB\n",
      "gptj_model_load: kv self size  =  896.00 MB\n",
      "gptj_model_load: ................................... done\n",
      "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n"
     ]
    }
   ],
   "source": [
    "model = GPT4All('/app/ggml-gpt4all-j-v1.3-groovy.bin',)\n",
    "model.model.set_thread_count(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcc71ec-1e79-4189-9281-8a0e5c3ed1fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function _response_callback in module gpt4all.pyllmodel:\n",
      "\n",
      "_response_callback(token_id, response)\n",
      "    # Empty response callback method that just prints response to be collected\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.model._response_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ddd063a-623f-47a2-9ae9-514bcb221238",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bachelor of Nursing Honours program is a specialized year after completing the Bachelor of Nursing degree, which focuses on research and professional development. It is designed to provide students with the skills and knowledge necessary for senior nursing or midwifery roles, as well as to pursue further education or research opportunities. The program offers a range of topics related to nursing practice and patient safety, including clinical risk management, chronic disease care and health delivery. Students will gain a deep understanding of the principles and ethics involved in health care research, as well as develop skills such as data management and research methods. The program also includes a range of practical skills, such\n",
      "CPU times: user 10min 47s, sys: 4.37 s, total: 10min 51s\n",
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Bachelor of Nursing Honours program is a specialized year after completing the Bachelor of Nursing degree, which focuses on research and professional development. It is designed to provide students with the skills and knowledge necessary for senior nursing or midwifery roles, as well as to pursue further education or research opportunities. The program offers a range of topics related to nursing practice and patient safety, including clinical risk management, chronic disease care and health delivery. Students will gain a deep understanding of the principles and ethics involved in health care research, as well as develop skills such as data management and research methods. The program also includes a range of practical skills, such'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.generate(prompt.format(overview=data.overview[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c62d6b1-b6d2-41d3-81ac-948d8a8c75d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, concat\n",
    "\n",
    "\n",
    "def _callback(token_id: int, response: str) -> bool:\n",
    "    global counter\n",
    "    if response.decode('utf-8') == '.':\n",
    "        # every time a . is detected is a new sentence\n",
    "        counter += 1\n",
    "    \n",
    "    # if the total number of sentences are less than 2\n",
    "    if counter < 2:\n",
    "        \n",
    "        # print them / process them - this will become calls to the /animateSay endpoint\n",
    "        print(response.decode('utf-8'), end='')\n",
    "        \n",
    "        # continue generation process\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        # reset sentence counter\n",
    "        counter = 0\n",
    "        print('.')\n",
    "        \n",
    "        # stop further generation\n",
    "        return False\n",
    "\n",
    "\n",
    "counter = 0\n",
    "data = read_csv('course-data-small.csv')[['course_name', 'overview']]\n",
    "model.model._response_callback = _callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e5e592-bda3-4b23-940c-42847cbbf5a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bachelor of Nursing Honours is a specialized year after completing an undergraduate degree in nursing. It is designed to provide students with the knowledge and research skills necessary for senior nursing roles or advanced professional training.\n",
      "\n",
      "CPU times: user 10min 27s, sys: 3.02 s, total: 10min 30s\n",
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Bachelor of Nursing Honours is a specialized year after completing an undergraduate degree in nursing. It is designed to provide students with the knowledge and research skills necessary for senior nursing roles or advanced professional training.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.generate(\n",
    "    prompt=prompt.format(overview=data.overview[0]), \n",
    "    streaming=True, temp=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628d1df4-51d1-4768-a5d7-88e599800a64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains           import RetrievalQA\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.llms             import GPT4All\n",
    "from langchain.embeddings       import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter    import CharacterTextSplitter\n",
    "from langchain.vectorstores     import Chroma\n",
    "from langchain.prompts          import PromptTemplate\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.callbacks.base   import BaseCallbackHandler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187eb214-8f2f-4449-959a-d4d54a327af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseCallbackHandler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcapitalize\u001b[39m(text):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([word\u001b[38;5;241m.\u001b[39mcapitalize() \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text\u001b[38;5;241m.\u001b[39msplit()])\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMainCallback\u001b[39;00m(\u001b[43mBaseCallbackHandler\u001b[49m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_sentences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseCallbackHandler' is not defined"
     ]
    }
   ],
   "source": [
    "def capitalize(text):\n",
    "    return \" \".join([word.capitalize() for word in text.split()])\n",
    "\n",
    "\n",
    "class MainCallback(BaseCallbackHandler):\n",
    "\n",
    "    def __init__(self, max_sentences=5, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs) \n",
    "        self.max_sentences = max_sentences\n",
    "        self.num_sentences = 0\n",
    "        self.raise_error = True\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        if token == '.':\n",
    "            self.num_sentences += 1\n",
    "            if self.num_sentences >= self.max_sentences:\n",
    "                print('Max senteces reached: ', self.num_sentences)\n",
    "            raise Exception('Dumb Exception.')\n",
    "        else:\n",
    "            try:\n",
    "                token.encode('utf-8')\n",
    "            except UnicodeDecodeError as e:\n",
    "                # take ascii equivalent of unicode char\n",
    "                token = ord(token)\n",
    "                    \n",
    "            # print('TOKEN: ', type(token), token, capitalize(token))\n",
    "    \n",
    "    def on_llm_end(self, response, *, run_id, parent_run_id=None, **kwargs):\n",
    "        print('The number of sentences is: ', self.num_sentences)\n",
    "        \n",
    "\n",
    "\n",
    "callback = MainCallback(max_sentences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460aedc4-a43b-4caa-aeaf-56902eaaf897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = read_csv('course-data-small.csv')[['course_name', 'overview']]\n",
    "data['content'] = data['course_name'] + ' ' + data.overview\n",
    "data['content'] = data.content.str.replace('’', '').str.replace('^', ' ')\n",
    "loader = DataFrameLoader(data[['content']], page_content_column='content')\n",
    "document = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b385d1a8-cd07-4cbd-a767-af12a6af6007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /app/ggml-gpt4all-j-v1.3-groovy.bin\n",
      "gptj_model_load: loading model from '/app/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
      "gptj_model_load: n_vocab = 50400\n",
      "gptj_model_load: n_ctx   = 2048\n",
      "gptj_model_load: n_embd  = 4096\n",
      "gptj_model_load: n_head  = 16\n",
      "gptj_model_load: n_layer = 28\n",
      "gptj_model_load: n_rot   = 64\n",
      "gptj_model_load: f16     = 2\n",
      "gptj_model_load: ggml ctx size = 5401.45 MB\n",
      "gptj_model_load: kv self size  =  896.00 MB\n",
      "gptj_model_load: ................................... done\n",
      "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n"
     ]
    }
   ],
   "source": [
    "# embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "# db = Chroma.from_documents(document, embeddings,)\n",
    "model_path = '/app/ggml-gpt4all-j-v1.3-groovy.bin'\n",
    "llm = GPT4All(model=model_path, verbose=False, n_threads=8, seed=42, temp=0.3, streaming=False, use_mlock=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8387d8c6-3840-464a-be2c-dbe103018e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestTestTestTestTestTest"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.client.model._response_callback(0, 'Test'.encode())\n",
    "llm.client.model._response_callback(0, 'Test'.encode())\n",
    "llm.client.model._response_callback(0, 'Test'.encode())\n",
    "llm.client.model._response_callback(0, 'Test'.encode())\n",
    "llm.client.model._response_callback(0, 'Test'.encode())\n",
    "llm.client.model._response_callback(0, 'Test'.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82127459-29f2-49da-9903-6bd0ae7d9f40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.use_mlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79628389-f9bf-419f-ba39-403898330d10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__class_vars__',\n",
       " '__config__',\n",
       " '__custom_root_type__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__exclude_fields__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_validators__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__include_fields__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__json_encoder__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__post_root_validators__',\n",
       " '__pre_root_validators__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__schema_cache__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__try_update_forward_refs__',\n",
       " '__validators__',\n",
       " '_abc_impl',\n",
       " '_acall',\n",
       " '_agenerate',\n",
       " '_calculate_keys',\n",
       " '_call',\n",
       " '_call_async',\n",
       " '_copy_and_set_values',\n",
       " '_decompose_class',\n",
       " '_default_params',\n",
       " '_enforce_dict_if_root',\n",
       " '_generate',\n",
       " '_get_value',\n",
       " '_identifying_params',\n",
       " '_init_private_attributes',\n",
       " '_iter',\n",
       " '_llm_type',\n",
       " '_model_param_names',\n",
       " 'agenerate',\n",
       " 'agenerate_prompt',\n",
       " 'all_required_field_names',\n",
       " 'allow_download',\n",
       " 'apredict',\n",
       " 'apredict_messages',\n",
       " 'backend',\n",
       " 'cache',\n",
       " 'callback_manager',\n",
       " 'callbacks',\n",
       " 'client',\n",
       " 'construct',\n",
       " 'context_erase',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'echo',\n",
       " 'embedding',\n",
       " 'f16_kv',\n",
       " 'from_orm',\n",
       " 'generate',\n",
       " 'generate_prompt',\n",
       " 'get_num_tokens',\n",
       " 'get_num_tokens_from_messages',\n",
       " 'get_token_ids',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_kwargs',\n",
       " 'lc_namespace',\n",
       " 'lc_secrets',\n",
       " 'lc_serializable',\n",
       " 'logits_all',\n",
       " 'model',\n",
       " 'n_batch',\n",
       " 'n_ctx',\n",
       " 'n_parts',\n",
       " 'n_predict',\n",
       " 'n_threads',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'predict',\n",
       " 'predict_messages',\n",
       " 'raise_deprecation',\n",
       " 'repeat_last_n',\n",
       " 'repeat_penalty',\n",
       " 'save',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'seed',\n",
       " 'set_verbose',\n",
       " 'stop',\n",
       " 'streaming',\n",
       " 'temp',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'top_k',\n",
       " 'top_p',\n",
       " 'update_forward_refs',\n",
       " 'use_mlock',\n",
       " 'validate',\n",
       " 'validate_environment',\n",
       " 'verbose',\n",
       " 'vocab_only']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e2cddb-8c14-47d8-87f1-b17f9d58aaad",
   "metadata": {
    "tags": []
   },
   "source": [
    "document[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d621fb1c-8ed4-47b2-8049-fdc6451e4253",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%time\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=False)\n",
    "temp = chain.run([document[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4676b86b-d444-409f-9936-2de6eeb1f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "    Summarize this overview in as few words as possible.\n",
    "    {overview}\n",
    "    In summary, \n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"overview\"], template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05c8995b-5921-4fb1-b070-1b10557e5df8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Summarize this overview in as few words as possible.\\n    Focusing on research, the honours year builds on the foundations established in your undergraduate degree. You will study a particular topic of professional interest in greater depth and create pathways to specialisations and further research or study. The Bachelor of Nursing (Honours) is a specialised year of study taken after the completion of a Bachelor of Nursing, entry to practice Master degree or combined degrees. For entry into senior nursing and midwifery roles there’s now an increasing industry expectation for graduates with high-level research and evaluation skills. Honours offers you a competitive edge in the job market and is designed to provide you with the knowledge and research skills to undertake a postgraduate research degree, advanced professional training or to pursue diverse employment opportunities. The School of Nursing and Midwifery offers research in areas influencing quality and patient safety in health care. These include: clinical risk and symptom management, chronic disease management, effective health delivery, health care ethics, decision making, aged care, midwifery and translational research. Throughout this course you will gain a deep understanding of the philosophies, ethics and principles of health care research; knowledge of a range of research approaches; skills in data management, methods and tools for research practice; and skills in planning, implementing and reporting research studies. This course will give you an understanding of how to develop a research proposal, from the identification of a research issue and literature review through to writing and submitting the proposal for approval by an ethics committee. You will undertake a research project and an individual research thesis in the area of nursing practice and develop evaluation and research skills in nursing practice and health service delivery. You will be qualified for rewarding roles in all areas of nursing including acute care/sub-acute care, emergency, aged care, paediatrics and rehabilitation; in hospitals, government departments, district health services, the education sector, business and private industry. Alternatively, you may decide to undertake a research degree such as a research Masters or Doctor of Philosophy (PhD).\\n    In summary, \\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(overview=data.overview[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0559ee5-7a32-4ab5-a665-d2aa9e5aeb8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bachelor's Degree is an undergraduate program that provides students with foundational knowledge about nursing practice through hands-on clinical experiences in hospitals/health facilities where they learn from experienced nurses who are experts at their field. The focus on the Honours Year, which follows after completion of a bachelor degree and before entry into professional programs such as Master��s or Doctoral degrees is to provide students with specialized knowledge about nursing practice through hands-on clinical experiences in hospitals/health facilities where they learn from experienced nurses who are experts at their field. The Bachelor's Degree program focuses on providing foundational knowledge, skills for the Honours Year and preparing them well enough so that when it comes time to enter professional programs like Master��s or Doctoral degrees, students will have a strong foundation in nursing practice with specialized expertise they can apply towards further education/career advancement.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Dumb Exception.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcourse_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(doc\u001b[38;5;241m.\u001b[39mcourse_name)\n\u001b[1;32m     14\u001b[0m temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(doc\u001b[38;5;241m.\u001b[39moverview)\n\u001b[1;32m     15\u001b[0m temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo_summarized\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverview\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverview\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# save dataframe every 5 rows\u001b[39;00m\n\u001b[1;32m     21\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/base.py:358\u001b[0m, in \u001b[0;36mBaseLLM.predict\u001b[0;34m(self, text, stop, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m     _stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(stop)\n\u001b[0;32m--> 358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/base.py:333\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`generate` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    336\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/base.py:203\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    204\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(output)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/base.py:195\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    191\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m), prompts, invocation_params\u001b[38;5;241m=\u001b[39mparams, options\u001b[38;5;241m=\u001b[39moptions\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 195\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/base.py:493\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m    492\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 493\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    495\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    496\u001b[0m     )\n\u001b[1;32m    497\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/gpt4all.py:210\u001b[0m, in \u001b[0;36mGPT4All._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m text_callback:\n\u001b[0;32m--> 210\u001b[0m         \u001b[43mtext_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m token\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/callbacks/manager.py:349\u001b[0m, in \u001b[0;36mCallbackManagerForLLMRun.on_llm_new_token\u001b[0;34m(self, token, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_llm_new_token\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     token: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    347\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run when LLM generates a new token.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     \u001b[43m_handle_event\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandlers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_llm_new_token\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore_llm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_run_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/callbacks/manager.py:206\u001b[0m, in \u001b[0;36m_handle_event\u001b[0;34m(handlers, event_name, ignore_condition_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m handler\u001b[38;5;241m.\u001b[39mraise_error:\n\u001b[0;32m--> 206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    207\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m callback: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/callbacks/manager.py:188\u001b[0m, in \u001b[0;36m_handle_event\u001b[0;34m(handlers, event_name, ignore_condition_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ignore_condition_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m    186\u001b[0m         handler, ignore_condition_name\n\u001b[1;32m    187\u001b[0m     ):\n\u001b[0;32m--> 188\u001b[0m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_chat_model_start\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mMainCallback.on_llm_new_token\u001b[0;34m(self, token, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_sentences \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_sentences:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax senteces reached: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_sentences)\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDumb Exception.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mException\u001b[0m: Dumb Exception."
     ]
    }
   ],
   "source": [
    "data = read_csv('course-data-small.csv')[['course_name', 'overview']].reset_index(drop=True)\n",
    "\n",
    "temp = {\n",
    "    'course_name': [], \n",
    "    'o_summarized': [], \n",
    "    'overview': []\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(temp)\n",
    "result_df.to_csv('gpt-summarized-info.csv', index=False)\n",
    "counter = 0\n",
    "for idx, doc in data.iterrows():\n",
    "    temp['course_name'].append(doc.course_name)\n",
    "    temp['overview'].append(doc.overview)\n",
    "    temp['o_summarized'].append(\n",
    "        llm.predict(\n",
    "            prompt.format(overview=doc.overview),\n",
    "        )\n",
    "    )\n",
    "    # save dataframe every 5 rows\n",
    "    counter += 1\n",
    "\n",
    "    # Save the data to the DataFrame every 5 rows\n",
    "    if counter % 5 == 0:\n",
    "        pd.DataFrame(temp).to_csv('gpt-summarized-info.csv', mode='a', index=False, header=False)\n",
    "        temp = {'course_name': [], 'o_summarized': [], 'overview': []}\n",
    "        print(f'\\rCompleted IDX: {idx} \\t| Counter: {counter}', end='', flush=True)\n",
    "        \n",
    "    break\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81891a0f-c524-4d77-9b3f-5f6bbaa61ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
