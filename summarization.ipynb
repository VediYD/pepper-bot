{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82aaecb-5f45-4df6-acb1-cbd802c3ac0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.llms             import GPT4All\n",
    "from langchain.prompts          import PromptTemplate\n",
    "\n",
    "from pandas import read_csv, concat, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f818b87-57dd-4a6e-8807-a45277615675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _callback(token_id: int, response: str) -> bool:\n",
    "    global counter, responses, four_sentences\n",
    "    \n",
    "    # save the summary tokens\n",
    "    responses.append(response.decode('utf-8'))\n",
    "    \n",
    "    if response.decode('utf-8') == '.':\n",
    "        # every time a . is detected is a new sentence\n",
    "        counter += 1\n",
    "    \n",
    "    # if the total number of sentences are less than 2\n",
    "    if counter < 4:\n",
    "        four_sentences = False\n",
    "        \n",
    "        # continue generation process\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        # reset sentence counter\n",
    "        counter = 0\n",
    "        four_sentences = True\n",
    "        \n",
    "        # stop further generation\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6035a85-3a3e-4f81-aeb9-27313465b502",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /app/ggml-gpt4all-j-v1.3-groovy.bin\n",
      "gptj_model_load: loading model from '/app/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
      "gptj_model_load: n_vocab = 50400\n",
      "gptj_model_load: n_ctx   = 2048\n",
      "gptj_model_load: n_embd  = 4096\n",
      "gptj_model_load: n_head  = 16\n",
      "gptj_model_load: n_layer = 28\n",
      "gptj_model_load: n_rot   = 64\n",
      "gptj_model_load: f16     = 2\n",
      "gptj_model_load: ggml ctx size = 5401.45 MB\n",
      "gptj_model_load: kv self size  =  896.00 MB\n",
      "gptj_model_load: ................................... done\n",
      "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n"
     ]
    }
   ],
   "source": [
    "# set global variables\n",
    "counter = 0\n",
    "responses = []\n",
    "four_sentences = False\n",
    "\n",
    "# load the data up for summarization\n",
    "data = read_csv('course-data-small.csv')[['course_name', 'overview']]\n",
    "\n",
    "# load the model\n",
    "model_path = '/app/ggml-gpt4all-j-v1.3-groovy.bin'\n",
    "llm = GPT4All(model=model_path, verbose=False, n_threads=8, seed=42, temp=0.3, streaming=False, use_mlock=True)\n",
    "\n",
    "# change the callback\n",
    "llm.client.model._response_callback = _callback\n",
    "\n",
    "# declare the prompt template\n",
    "template = \"\"\"\n",
    "    Summarize this overview in as few words as possible.\n",
    "    {overview}\n",
    "    In summary, \n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"overview\"], template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15f30cea-436b-4402-ae30-9ad62220fcd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT-J: reached the end of the context window so resizing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT-J: reached the end of the context window so resizing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Completed IDX: 4 \t| Counter: 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'course_name': [], 'o_summarized': [], 'overview': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = {\n",
    "    'course_name': [], \n",
    "    'o_summarized': [], \n",
    "    'overview': []\n",
    "}\n",
    "\n",
    "result_df = DataFrame(temp)\n",
    "result_df.to_csv('gpt-summarized-info.csv', index=False)\n",
    "row_counter = 0\n",
    "\n",
    "for idx, doc in data.iterrows():\n",
    "    temp['course_name'].append(doc.course_name)\n",
    "    temp['overview'].append(doc.overview)\n",
    "    \n",
    "    prompt = prompt.format(overview=doc.overview)\n",
    "    # generate responses until the global counter \n",
    "    llm.predict(prompt,)\n",
    "    \n",
    "    while not four_sentences:\n",
    "        new_prompt = prompt + ''.join(responses)\n",
    "        llm.predict(new_prompt)\n",
    "    \n",
    "    temp['o_summarized'].append(''.join(responses))\n",
    "    \n",
    "    # save dataframe every 5 rows\n",
    "    row_counter += 1\n",
    "    \n",
    "    # Save the data to the DataFrame every 5 rows\n",
    "    if row_counter % 5 == 0:\n",
    "        DataFrame(temp).to_csv('gpt-summarized-info.csv', mode='a', index=False, header=False)\n",
    "        temp = {'course_name': [], 'o_summarized': [], 'overview': []}\n",
    "        print(f'\\rCompleted IDX: {idx} \\t| Counter: {counter}', end='', flush=True)\n",
    "    \n",
    "    # reset the response variable\n",
    "    responses = []\n",
    "    four_sentences = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec9e4d-5ee4-4ebd-b0f1-2444af36e7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c89e2589-e2a4-486c-b3a4-c67fa43e45ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28cd5c-0b29-403a-bcdd-09d2a01b3eea",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2a882-fb02-41aa-aae8-c7ce216035d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "from gpt4all import GPT4All"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cc8419-2ea9-42a7-aca5-a6e40508fa37",
   "metadata": {
    "tags": []
   },
   "source": [
    "model = GPT4All('/app/ggml-gpt4all-j-v1.3-groovy.bin',)\n",
    "model.model.set_thread_count(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0793846-f4de-4daa-b1bb-07299fc647cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "help(model.model._response_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158820dd-ac96-452f-90f8-6dc054187044",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%time\n",
    "model.generate(prompt.format(overview=data.overview[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a6f33-12a8-411c-8ff9-b07a910fcf89",
   "metadata": {
    "tags": []
   },
   "source": [
    "from pandas import read_csv, concat\n",
    "\n",
    "\n",
    "def _callback(token_id: int, response: str) -> bool:\n",
    "    global counter\n",
    "    if response.decode('utf-8') == '.':\n",
    "        # every time a . is detected is a new sentence\n",
    "        counter += 1\n",
    "    \n",
    "    # if the total number of sentences are less than 2\n",
    "    if counter < 2:\n",
    "        \n",
    "        # print them / process them - this will become calls to the /animateSay endpoint\n",
    "        print(response.decode('utf-8'), end='')\n",
    "        \n",
    "        # continue generation process\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        # reset sentence counter\n",
    "        counter = 0\n",
    "        print('.')\n",
    "        \n",
    "        # stop further generation\n",
    "        return False\n",
    "\n",
    "\n",
    "counter = 0\n",
    "data = read_csv('course-data-small.csv')[['course_name', 'overview']]\n",
    "model.model._response_callback = _callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff51044-f3e4-4f3b-8631-327dd37f5bfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%time\n",
    "model.generate(\n",
    "    prompt=prompt.format(overview=data.overview[0]), \n",
    "    streaming=True, temp=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8584abb3-c23d-43cb-a4aa-139f4034ab74",
   "metadata": {
    "tags": []
   },
   "source": [
    "from langchain.chains           import RetrievalQA\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.llms             import GPT4All\n",
    "from langchain.embeddings       import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter    import CharacterTextSplitter\n",
    "from langchain.vectorstores     import Chroma\n",
    "from langchain.prompts          import PromptTemplate\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.callbacks.base   import BaseCallbackHandler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv, concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adfa85d-f868-41ce-a323-810bdd93aceb",
   "metadata": {
    "tags": []
   },
   "source": [
    "def capitalize(text):\n",
    "    return \" \".join([word.capitalize() for word in text.split()])\n",
    "\n",
    "\n",
    "class MainCallback(BaseCallbackHandler):\n",
    "\n",
    "    def __init__(self, max_sentences=5, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs) \n",
    "        self.max_sentences = max_sentences\n",
    "        self.num_sentences = 0\n",
    "        self.raise_error = True\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        if token == '.':\n",
    "            self.num_sentences += 1\n",
    "            if self.num_sentences >= self.max_sentences:\n",
    "                print('Max senteces reached: ', self.num_sentences)\n",
    "            raise Exception('Dumb Exception.')\n",
    "        else:\n",
    "            try:\n",
    "                token.encode('utf-8')\n",
    "            except UnicodeDecodeError as e:\n",
    "                # take ascii equivalent of unicode char\n",
    "                token = ord(token)\n",
    "                    \n",
    "            # print('TOKEN: ', type(token), token, capitalize(token))\n",
    "    \n",
    "    def on_llm_end(self, response, *, run_id, parent_run_id=None, **kwargs):\n",
    "        print('The number of sentences is: ', self.num_sentences)\n",
    "        \n",
    "\n",
    "\n",
    "callback = MainCallback(max_sentences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9686af-7533-4a3a-adae-6c290220a1bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "data = read_csv('course-data-small.csv')[['course_name', 'overview']]\n",
    "data['content'] = data['course_name'] + ' ' + data.overview\n",
    "data['content'] = data.content.str.replace('â€™', '').str.replace('^', ' ')\n",
    "loader = DataFrameLoader(data[['content']], page_content_column='content')\n",
    "document = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01753882-af17-4831-b61c-62f15db51485",
   "metadata": {
    "tags": []
   },
   "source": [
    "# embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "# db = Chroma.from_documents(document, embeddings,)\n",
    "model_path = '/app/ggml-gpt4all-j-v1.3-groovy.bin'\n",
    "llm = GPT4All(model=model_path, verbose=False, n_threads=8, seed=42, temp=0.3, streaming=False, use_mlock=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b1e491-6bed-481f-b754-cd0414e45439",
   "metadata": {
    "tags": []
   },
   "source": [
    "llm.client.model._response_callback(0, 'Test'.encode())\n",
    "llm.client.model._response_callback(0, 'Test'.encode())\n",
    "llm.client.model._response_callback(0, 'Test'.encode())\n",
    "llm.client.model._response_callback(0, 'Test'.encode())\n",
    "llm.client.model._response_callback(0, 'Test'.encode())\n",
    "llm.client.model._response_callback(0, 'Test'.encode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c12a593-61a5-4d39-948e-e1a117c0a9b1",
   "metadata": {},
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "    Summarize this overview in as few words as possible.\n",
    "    {overview}\n",
    "    In summary, \n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"overview\"], template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39986dd-5d29-424d-860c-34ff42eac8ae",
   "metadata": {},
   "source": [
    "prompt.format(overview=data.overview[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad8f935-1dc6-4a8b-a93d-1a3359626a9d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "data = read_csv('course-data-small.csv')[['course_name', 'overview']].reset_index(drop=True)\n",
    "\n",
    "temp = {\n",
    "    'course_name': [], \n",
    "    'o_summarized': [], \n",
    "    'overview': []\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(temp)\n",
    "result_df.to_csv('gpt-summarized-info.csv', index=False)\n",
    "counter = 0\n",
    "for idx, doc in data.iterrows():\n",
    "    temp['course_name'].append(doc.course_name)\n",
    "    temp['overview'].append(doc.overview)\n",
    "    temp['o_summarized'].append(\n",
    "        llm.predict(\n",
    "            prompt.format(overview=doc.overview),\n",
    "        )\n",
    "    )\n",
    "    # save dataframe every 5 rows\n",
    "    counter += 1\n",
    "\n",
    "    # Save the data to the DataFrame every 5 rows\n",
    "    if counter % 5 == 0:\n",
    "        pd.DataFrame(temp).to_csv('gpt-summarized-info.csv', mode='a', index=False, header=False)\n",
    "        temp = {'course_name': [], 'o_summarized': [], 'overview': []}\n",
    "        print(f'\\rCompleted IDX: {idx} \\t| Counter: {counter}', end='', flush=True)\n",
    "        \n",
    "    break\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81891a0f-c524-4d77-9b3f-5f6bbaa61ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
