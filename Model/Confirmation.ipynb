{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35e0f18",
   "metadata": {},
   "source": [
    "## Before Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81911e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.6.1-cp310-cp310-win_amd64.whl (12.0 MB)\n",
      "     ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.2/12.0 MB 6.9 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.8/12.0 MB 9.8 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.3/12.0 MB 10.4 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 1.9/12.0 MB 11.3 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 2.3/12.0 MB 10.6 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 3.2/12.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 4.0/12.0 MB 12.7 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 4.8/12.0 MB 13.3 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.4/12.0 MB 13.3 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 5.9/12.0 MB 13.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 6.8/12.0 MB 13.5 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.3/12.0 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 7.8/12.0 MB 13.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 8.6/12.0 MB 13.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.2/12.0 MB 13.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 9.6/12.0 MB 13.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.1/12.0 MB 13.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 10.7/12.0 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 11.3/12.0 MB 13.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  11.8/12.0 MB 13.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.0/12.0 MB 13.1 MB/s eta 0:00:00\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp310-cp310-win_amd64.whl (94 kB)\n",
      "     ---------------------------------------- 0.0/94.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 94.7/94.7 kB 5.3 MB/s eta 0:00:00\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.2-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 0.0/48.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.9/48.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from spacy) (2.28.2)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp310-cp310-win_amd64.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.9-py3-none-any.whl (17 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.7-cp310-cp310-win_amd64.whl (481 kB)\n",
      "     ---------------------------------------- 0.0/481.6 kB ? eta -:--:--\n",
      "     ------------------------------------- 481.6/481.6 kB 31.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from spacy) (66.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.12-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ------------------------- -------------- 1.0/1.5 MB 20.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 15.8 MB/s eta 0:00:00\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.1.1-py3-none-any.whl (370 kB)\n",
      "     ---------------------------------------- 0.0/370.9 kB ? eta -:--:--\n",
      "     ------------------------------------- 370.9/370.9 kB 11.3 MB/s eta 0:00:00\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 45.9/45.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from spacy) (23.0)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting pydantic-core==2.4.0\n",
      "  Downloading pydantic_core-2.4.0-cp310-none-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------- ----------------------- 0.7/1.7 MB 22.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.4/1.7 MB 17.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.4/1.7 MB 17.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 10.9 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.10-cp310-cp310-win_amd64.whl (7.4 MB)\n",
      "     ---------------------------------------- 0.0/7.4 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.4/7.4 MB 13.9 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 0.8/7.4 MB 9.8 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 1.3/7.4 MB 10.5 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 1.9/7.4 MB 11.0 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 2.4/7.4 MB 10.8 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.7/7.4 MB 10.2 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 3.3/7.4 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.9/7.4 MB 11.3 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 4.4/7.4 MB 11.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 5.0/7.4 MB 11.4 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 5.6/7.4 MB 11.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 6.1/7.4 MB 11.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 6.6/7.4 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 7.2/7.4 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.4/7.4 MB 11.3 MB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Installing collected packages: cymem, wasabi, typing-extensions, spacy-loggers, spacy-legacy, smart-open, murmurhash, langcodes, catalogue, blis, annotated-types, typer, srsly, pydantic-core, preshed, pydantic, pathy, confection, thinc, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed annotated-types-0.5.0 blis-0.7.10 catalogue-2.0.9 confection-0.1.1 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.2 preshed-3.0.8 pydantic-2.1.1 pydantic-core-2.4.0 smart-open-6.3.0 spacy-3.6.1 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.7 thinc-8.1.12 typer-0.9.0 typing-extensions-4.7.1 wasabi-1.1.2\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# Before running!\n",
    "# !pip install tensorflow==2.10.1\n",
    "# !pip install keras==2.10.0\n",
    "# !pip install scapy==3.6.1\n",
    "\n",
    "# You need to do this once\n",
    "# spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed35a1b6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd0cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load pre-trained spaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "462826ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Responses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the available accommodation options f...</td>\n",
       "      <td>Accomodation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you provide me with information about th...</td>\n",
       "      <td>Accomodation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the housing costs like for students w...</td>\n",
       "      <td>Accomodation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you recommend any off-campus accommodation...</td>\n",
       "      <td>Accomodation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the facilities and amenities offered ...</td>\n",
       "      <td>Accomodation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>Bachelor of Zoology and Animal Science</td>\n",
       "      <td>Courses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Diploma of AI</td>\n",
       "      <td>Courses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Bachelor of AI</td>\n",
       "      <td>Courses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>Masters of AI</td>\n",
       "      <td>Courses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>AI</td>\n",
       "      <td>Courses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Responses         Class\n",
       "0    What are the available accommodation options f...  Accomodation\n",
       "1    Could you provide me with information about th...  Accomodation\n",
       "2    What are the housing costs like for students w...  Accomodation\n",
       "3    Can you recommend any off-campus accommodation...  Accomodation\n",
       "4    What are the facilities and amenities offered ...  Accomodation\n",
       "..                                                 ...           ...\n",
       "674             Bachelor of Zoology and Animal Science       Courses\n",
       "675                                      Diploma of AI       Courses\n",
       "676                                     Bachelor of AI       Courses\n",
       "677                                      Masters of AI       Courses\n",
       "678                                                 AI       Courses\n",
       "\n",
       "[679 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from the Excel file into a DataFrame\n",
    "data = pd.read_excel(\"Questiondata.xlsx\") \n",
    "\n",
    "# Rename headers\n",
    "data.columns = ['Responses', 'Class']\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b78e44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "Courses         408\n",
       "General          91\n",
       "Accomodation     90\n",
       "Activities       90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd7de2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences and classes from the DataFrame\n",
    "sentences = data[\"Responses\"].tolist()\n",
    "classes = data[\"Class\"].tolist()\n",
    "\n",
    "# Lowercase sentences\n",
    "sentences = [sentence.lower() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610a7332",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29170dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are there any information sessions about deakinres coming up\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Remove punctuation\n",
    "processed_sentences = [sentence.translate(str.maketrans('', '', string.punctuation)) for sentence in sentences]\n",
    "print(processed_sentences[np.random.randint(0, len(X))])\n",
    "# Tokenize sentences and extract word vectors\n",
    "X = np.array([nlp(sentence).vector for sentence in processed_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "789dfc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(classes)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673fc1af",
   "metadata": {},
   "source": [
    "### Saving the label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b3cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the encoder\n",
    "with open('label_encoder2.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Load the encoder\n",
    "with open('label_encoder2.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a30520",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18193d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "611/611 [==============================] - 5s 7ms/step - loss: 0.8955 - accuracy: 0.7414 - val_loss: 0.4522 - val_accuracy: 0.8824\n",
      "Epoch 2/15\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 0.5563 - accuracy: 0.8380 - val_loss: 0.9275 - val_accuracy: 0.7794\n",
      "Epoch 3/15\n",
      "611/611 [==============================] - 4s 6ms/step - loss: 0.3239 - accuracy: 0.8936 - val_loss: 0.4632 - val_accuracy: 0.8088\n",
      "Epoch 4/15\n",
      "611/611 [==============================] - 4s 6ms/step - loss: 0.2843 - accuracy: 0.9018 - val_loss: 0.2448 - val_accuracy: 0.8676\n",
      "Epoch 5/15\n",
      "611/611 [==============================] - 4s 6ms/step - loss: 0.1583 - accuracy: 0.9411 - val_loss: 0.2758 - val_accuracy: 0.8676\n",
      "Epoch 6/15\n",
      "611/611 [==============================] - 4s 6ms/step - loss: 0.1727 - accuracy: 0.9444 - val_loss: 0.3169 - val_accuracy: 0.9118\n",
      "Epoch 7/15\n",
      "611/611 [==============================] - 4s 7ms/step - loss: 0.1758 - accuracy: 0.9460 - val_loss: 0.2507 - val_accuracy: 0.9265\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.9265\n",
      "Test Accuracy: 0.9264705777168274\n"
     ]
    }
   ],
   "source": [
    "# Callback\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Build a neural network model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=15, batch_size=1, \n",
    "    verbose=1, \n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca721e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a `.keras` zip archive.\n",
    "model.save('Classification.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be97e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('Classification.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b935d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n",
      "Accomodation\n",
      "[0.99999917]\n"
     ]
    }
   ],
   "source": [
    "sentence = nlp('Where can I stay at deakin?'.lower()).vector\n",
    "predicted_labels = model.predict(np.array([sentence]))\n",
    "predicted_label = label_encoder.inverse_transform(predicted_labels.argmax(axis=1))[0]\n",
    "print(predicted_label)\n",
    "\n",
    "predicted_prob = predicted_labels[0][predicted_labels.argmax(axis=1)]\n",
    "print(predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c59b7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "Courses\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "sentence = nlp('Master of AI'.lower()).vector\n",
    "predicted_labels = model.predict(np.array([sentence]))\n",
    "predicted_label = label_encoder.inverse_transform(predicted_labels.argmax(axis=1))[0]\n",
    "print(predicted_label)\n",
    "\n",
    "predicted_prob = predicted_labels[0][predicted_labels.argmax(axis=1)]\n",
    "print(predicted_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4b1d79",
   "metadata": {},
   "source": [
    "## Flask Function Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd7238b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abv_thresh': True, 'label': 'Courses'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "res = requests.post(\n",
    "    'http://10.104.23.130:8891/classifyResponse',\n",
    "    json={\n",
    "        'sentence': 'I want to know about courses related to AI and Data Science',\n",
    "        'threshold': 0.95\n",
    "    }\n",
    ")\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc144707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Courses'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.json()['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fc5d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "# Pad sequences to a fixed length\n",
    "max_sequence_length = 20  # Choose an appropriate value\n",
    "X = pad_sequences(X, maxlen=max_sequence_length, padding='post', dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8c9b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21a41aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 20, 128)           165120    \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 20, 64)            37248     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20, 64)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20, 4)             260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 202,628\n",
      "Trainable params: 202,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU, Dropout, Dense\n",
    "\n",
    "mega_model = tf.keras.Sequential()\n",
    "mega_model.add(GRU(128, input_shape=(20, X.shape[1],), return_sequences=True))\n",
    "mega_model.add(GRU(64, return_sequences=True))\n",
    "mega_model.add(Dropout(0.2))\n",
    "mega_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "mega_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "mega_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32fbb4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 20, 300), found shape=(None, 300)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mega_model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m11\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n",
      "File \u001b[1;32mc:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filez_plt3yi.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\sudak\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 20, 300), found shape=(None, 300)\n"
     ]
    }
   ],
   "source": [
    "mega_model.fit(X_train, y_train, epochs=11, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ca001d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CourseName</th>\n",
       "      <th>locationText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H911</td>\n",
       "      <td>Doctor of Medicine</td>\n",
       "      <td>This course is offered with blended delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M539</td>\n",
       "      <td>Executive Graduate Certificate of Sport Business</td>\n",
       "      <td>This course is offered Online only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M709</td>\n",
       "      <td>Executive Master of Sport Business</td>\n",
       "      <td>This course is offered Online only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E506</td>\n",
       "      <td>Graduate Certificate of Adult, Vocational Educ...</td>\n",
       "      <td>This course is offered Online only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H575</td>\n",
       "      <td>Graduate Certificate of Advanced Nursing</td>\n",
       "      <td>This course is offered Online only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>S369</td>\n",
       "      <td>Bachelor of Zoology and Animal Science</td>\n",
       "      <td>This course is offered at Geelong Waurn Ponds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>A221</td>\n",
       "      <td>Diploma of Arabic</td>\n",
       "      <td>This course is offered at Melbourne Burwood Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>A222</td>\n",
       "      <td>Diploma of Chinese</td>\n",
       "      <td>This course is offered at Melbourne Burwood an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>A223</td>\n",
       "      <td>Diploma of Indonesian</td>\n",
       "      <td>This course is offered at Melbourne Burwood an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>A224</td>\n",
       "      <td>Diploma of Spanish</td>\n",
       "      <td>This course is offered at Melbourne Burwood an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                         CourseName   \n",
       "0    H911                                 Doctor of Medicine  \\\n",
       "1    M539   Executive Graduate Certificate of Sport Business   \n",
       "2    M709                 Executive Master of Sport Business   \n",
       "3    E506  Graduate Certificate of Adult, Vocational Educ...   \n",
       "4    H575           Graduate Certificate of Advanced Nursing   \n",
       "..    ...                                                ...   \n",
       "326  S369             Bachelor of Zoology and Animal Science   \n",
       "327  A221                                  Diploma of Arabic   \n",
       "328  A222                                 Diploma of Chinese   \n",
       "329  A223                              Diploma of Indonesian   \n",
       "330  A224                                 Diploma of Spanish   \n",
       "\n",
       "                                          locationText  \n",
       "0         This course is offered with blended delivery  \n",
       "1                   This course is offered Online only  \n",
       "2                   This course is offered Online only  \n",
       "3                   This course is offered Online only  \n",
       "4                   This course is offered Online only  \n",
       "..                                                 ...  \n",
       "326  This course is offered at Geelong Waurn Ponds ...  \n",
       "327  This course is offered at Melbourne Burwood Ca...  \n",
       "328  This course is offered at Melbourne Burwood an...  \n",
       "329  This course is offered at Melbourne Burwood an...  \n",
       "330  This course is offered at Melbourne Burwood an...  \n",
       "\n",
       "[331 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courseName = pd.read_csv('https://raw.githubusercontent.com/VediYD/pepper-bot/dev-gpt-dev/textbyID.csv')\n",
    "courseName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b62968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "courseName.to_csv('courseName.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
